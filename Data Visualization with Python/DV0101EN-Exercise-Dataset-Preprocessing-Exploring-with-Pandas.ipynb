{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Exploring and pre-processing a dataset using Pandas \n",
    "\n",
    "\n",
    "Estimated time needed: **30** minutes\n",
    "    \n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "* Explore the dataset\n",
    "* Pre-process dataset as required (may be for visualization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The aim of this lab is to provide you a refresher on the **Pandas** library, so that you can pre-process and anlyse the datasets before applying data visualization techniques on it. This lab will work as acrash course on *pandas*. if you are interested in learning more about the *pandas* library, detailed description and explanation of how to use it and how to clean, munge, and process data stored in a *pandas* dataframe are provided in our course [**Data Analysis with Python**](https://www.coursera.org/learn/data-analysis-with-python?specialization=ibm-data-analyst) and [**Python for Applied Data Science**](https://www.coursera.org/learn/python-for-applied-data-science-ai?specialization=ibm-data-analyst)\n",
    "\n",
    "------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "1. [Exploring Datasets with *pandas*](#0)<br>\n",
    "2. [The Dataset: Immigration to Canada from 1980 to 2013](#1)<br>\n",
    "3. [*pandas* Basics](#2) <br>\n",
    "4. [*pandas* Intermediate: Indexing and Selection](#3) <br>\n",
    "5. [*pandas* Filtering based on a criteria](#4)<br>\n",
    "6. [*pandas* Sorting Values](#5)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Datasets with *pandas* <a id=\"0\"></a>\n",
    "\n",
    "*pandas* is an essential data analysis toolkit for Python. From their [website](http://pandas.pydata.org/):\n",
    ">*pandas* is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, **real world** data analysis in Python.\n",
    "\n",
    "The course heavily relies on *pandas* for data wrangling, analysis, and visualization. We encourage you to spend some time and familiarize yourself with the *pandas* API Reference: http://pandas.pydata.org/pandas-docs/stable/api.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset: Immigration to Canada from 1980 to 2013 <a id=\"1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Source: [International migration flows to and from selected countries - The 2015 revision](https://www.un.org/development/desa/pd/data/international-migration-flows).\n",
    "\n",
    "The dataset contains annual data on the flows of international immigrants as recorded by the countries of destination. The data presents both inflows and outflows according to the place of birth, citizenship or place of previous / next residence both for foreigners and nationals. The current version presents data pertaining to 45 countries.\n",
    "\n",
    "In this lab, we will focus on the Canadian immigration data.\n",
    "\n",
    "![Data Preview](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DV0101EN-SkillsNetwork/labs/Module%201/images/DataSnapshot.png)\n",
    "\n",
    " The Canada Immigration dataset can be fetched from <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DV0101EN-SkillsNetwork/Data%20Files/Canada.xlsx\">here</a>.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *pandas* Basics<a id=\"2\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is install **openpyxl** (formerly **xlrd**), a module that *pandas* requires to read Excel files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: mamba\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab_server==2.8.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::jupyter==1.0.0=py39hecd8cb5_7\n",
      "  - defaults/noarch::nbclient==0.5.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-repo-cli==1.0.4=pyhd3eb1b0_0\n",
      "  - conda-forge/osx-64::jupyter_nbextensions_configurator==0.4.1=py39h6e9494a_2\n",
      "  - defaults/osx-64::nbconvert==6.1.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::bkcharts==0.2=py39hecd8cb5_0\n",
      "  - defaults/noarch::nbclassic==0.2.6=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::notebook==6.4.5=py39hecd8cb5_0\n",
      "  - conda-forge/noarch::jupyter_contrib_core==0.3.3=py_2\n",
      "  - defaults/osx-64::anaconda==2021.11=py39_0\n",
      "  - defaults/osx-64::anaconda-client==1.9.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::jupyterlab==3.2.1=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::spyder==5.1.5=py39hecd8cb5_1\n",
      "  - defaults/osx-64::statsmodels==0.12.2=py39h9ed2024_0\n",
      "  - defaults/noarch::ipywidgets==7.6.5=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::jupyter_server==1.4.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::seaborn==0.11.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::dask==2021.10.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::widgetsnbextension==3.5.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::anaconda-project==0.10.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda-navigator==2.1.1=py39_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab_server==2.8.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::jupyter==1.0.0=py39hecd8cb5_7\n",
      "  - defaults/noarch::nbclient==0.5.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-repo-cli==1.0.4=pyhd3eb1b0_0\n",
      "  - conda-forge/osx-64::jupyter_nbextensions_configurator==0.4.1=py39h6e9494a_2\n",
      "  - defaults/osx-64::nbconvert==6.1.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::bkcharts==0.2=py39hecd8cb5_0\n",
      "  - defaults/noarch::nbclassic==0.2.6=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::notebook==6.4.5=py39hecd8cb5_0\n",
      "  - conda-forge/noarch::jupyter_contrib_core==0.3.3=py_2\n",
      "  - defaults/osx-64::anaconda==2021.11=py39_0\n",
      "  - defaults/osx-64::anaconda-client==1.9.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::jupyterlab==3.2.1=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::spyder==5.1.5=py39hecd8cb5_1\n",
      "  - defaults/osx-64::statsmodels==0.12.2=py39h9ed2024_0\n",
      "  - defaults/noarch::ipywidgets==7.6.5=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::jupyter_server==1.4.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::seaborn==0.11.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::dask==2021.10.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::widgetsnbextension==3.5.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::anaconda-project==0.10.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda-navigator==2.1.1=py39_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.11.0\n",
      "  latest version: 23.5.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/tobiasgrassani/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - mamba\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-2021.11  |           py39_0           7 KB\n",
      "    anaconda-custom            |           py39_2          13 KB\n",
      "    ca-certificates-2023.7.22  |       h8857fd0_0         146 KB  conda-forge\n",
      "    certifi-2023.7.22          |     pyhd8ed1ab_0         150 KB  conda-forge\n",
      "    conda-4.12.0               |   py39h6e9494a_0         1.0 MB  conda-forge\n",
      "    libsolv-0.7.19             |       hcf210ce_5         405 KB  conda-forge\n",
      "    mamba-0.7.6                |   py39h2f6f512_0         580 KB  conda-forge\n",
      "    nbformat-5.9.1             |     pyhd8ed1ab_0          98 KB  conda-forge\n",
      "    openssl-1.1.1u             |       h8a1eda9_0         1.7 MB  conda-forge\n",
      "    pandas-1.4.1               |   py39h4d6be9b_0        12.0 MB  conda-forge\n",
      "    python-fastjsonschema-2.17.1|     pyhd8ed1ab_0         220 KB  conda-forge\n",
      "    reproc-14.2.3              |       h0d85af4_0          26 KB  conda-forge\n",
      "    reproc-cpp-14.2.3          |       he49afe7_0          18 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        16.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _anaconda_depends  pkgs/main/osx-64::_anaconda_depends-2021.11-py39_0\n",
      "  libsolv            conda-forge/osx-64::libsolv-0.7.19-hcf210ce_5\n",
      "  mamba              conda-forge/osx-64::mamba-0.7.6-py39h2f6f512_0\n",
      "  nbformat           conda-forge/noarch::nbformat-5.9.1-pyhd8ed1ab_0\n",
      "  pandas             conda-forge/osx-64::pandas-1.4.1-py39h4d6be9b_0\n",
      "  python-fastjsonsc~ conda-forge/noarch::python-fastjsonschema-2.17.1-pyhd8ed1ab_0\n",
      "  reproc             conda-forge/osx-64::reproc-14.2.3-h0d85af4_0\n",
      "  reproc-cpp         conda-forge/osx-64::reproc-cpp-14.2.3-he49afe7_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.10.26~ --> conda-forge::ca-certificates-2023.7.22-h8857fd0_0\n",
      "  certifi            pkgs/main/osx-64::certifi-2021.10.8-p~ --> conda-forge/noarch::certifi-2023.7.22-pyhd8ed1ab_0\n",
      "  conda              pkgs/main::conda-4.11.0-py39hecd8cb5_0 --> conda-forge::conda-4.12.0-py39h6e9494a_0\n",
      "  openssl              pkgs/main::openssl-1.1.1l-h9ed2024_0 --> conda-forge::openssl-1.1.1u-h8a1eda9_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  anaconda                                   2021.11-py39_0 --> custom-py39_2\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n",
      "^C\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n",
      "^C\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / ^C\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!conda install -c conda-forge mamba\n",
    "!conda install -c \"conda-forge/label/broken\" mamba\n",
    "!conda install -c \"conda-forge/label/cf202003\" mamba\n",
    "!conda install -c \"conda-forge/label/mamba-alpha\" mamba \n",
    "!mamba install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab_server==2.8.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::jupyter==1.0.0=py39hecd8cb5_7\n",
      "  - defaults/noarch::nbclient==0.5.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-repo-cli==1.0.4=pyhd3eb1b0_0\n",
      "  - conda-forge/osx-64::jupyter_nbextensions_configurator==0.4.1=py39h6e9494a_2\n",
      "  - defaults/osx-64::nbconvert==6.1.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::bkcharts==0.2=py39hecd8cb5_0\n",
      "  - defaults/noarch::nbclassic==0.2.6=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::notebook==6.4.5=py39hecd8cb5_0\n",
      "  - conda-forge/noarch::jupyter_contrib_core==0.3.3=py_2\n",
      "  - defaults/osx-64::anaconda==2021.11=py39_0\n",
      "  - defaults/osx-64::anaconda-client==1.9.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::jupyterlab==3.2.1=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::spyder==5.1.5=py39hecd8cb5_1\n",
      "  - defaults/osx-64::statsmodels==0.12.2=py39h9ed2024_0\n",
      "  - defaults/noarch::ipywidgets==7.6.5=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::jupyter_server==1.4.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::seaborn==0.11.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::dask==2021.10.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::widgetsnbextension==3.5.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::anaconda-project==0.10.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda-navigator==2.1.1=py39_0\n",
      "failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab_server==2.8.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::jupyter==1.0.0=py39hecd8cb5_7\n",
      "  - defaults/noarch::nbclient==0.5.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-repo-cli==1.0.4=pyhd3eb1b0_0\n",
      "  - conda-forge/osx-64::jupyter_nbextensions_configurator==0.4.1=py39h6e9494a_2\n",
      "  - defaults/osx-64::nbconvert==6.1.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::bkcharts==0.2=py39hecd8cb5_0\n",
      "  - defaults/noarch::nbclassic==0.2.6=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::notebook==6.4.5=py39hecd8cb5_0\n",
      "  - conda-forge/noarch::jupyter_contrib_core==0.3.3=py_2\n",
      "  - defaults/osx-64::anaconda==2021.11=py39_0\n",
      "  - defaults/osx-64::anaconda-client==1.9.0=py39hecd8cb5_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::jupyterlab==3.2.1=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::spyder==5.1.5=py39hecd8cb5_1\n",
      "  - defaults/osx-64::statsmodels==0.12.2=py39h9ed2024_0\n",
      "  - defaults/noarch::ipywidgets==7.6.5=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::jupyter_server==1.4.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::seaborn==0.11.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::dask==2021.10.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::widgetsnbextension==3.5.1=py39hecd8cb5_0\n",
      "  - defaults/noarch::anaconda-project==0.10.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda-navigator==2.1.1=py39_0\n",
      "/ "
     ]
    }
   ],
   "source": [
    "!conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll do is import two key data analysis modules: *pandas* and *numpy*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # useful for many scientific computing in Python\n",
    "import pandas as pd # primary data structure library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download and import our primary Canadian Immigration dataset using *pandas*'s `read_excel()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jw/1m1_rnj17jq7ftknxfm0mmmr0000gn/T/ipykernel_5569/91686913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_can = pd.read_excel(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DV0101EN-SkillsNetwork/Data%20Files/Canada.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Canada by Citizenship'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     skipfooter=2)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;31m# N.B. xlrd.Book has a read attribute too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'xls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_FORMAT_DESCRIPTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'; not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     bk = open_workbook_xls(\n",
      "\u001b[0;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "df_can = pd.read_excel(\n",
    "    'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DV0101EN-SkillsNetwork/Data%20Files/Canada.xlsx',\n",
    "    sheet_name='Canada by Citizenship',\n",
    "    skiprows=range(20),\n",
    "    skipfooter=2)\n",
    "\n",
    "print('Data read into a pandas dataframe!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the top 5 rows of the dataset using the `head()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.head()\n",
    "# tip: You can specify the number of rows you'd like to see as follows: df_can.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the bottom 5 rows of the dataset using the `tail()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing a dataset, it's always a good idea to start by getting basic information about your dataframe. We can do this by using the `info()` method.\n",
    "\n",
    "This method can be used to get a short summary of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the list of column headers we can call upon the data frame's `columns` instance variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to get the list of indices we use the `.index` instance variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The default type of intance variables `index` and `columns` are **NOT** `list`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_can.columns))\n",
    "print(type(df_can.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the index and columns as lists, we can use the `tolist()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_can.columns.tolist()))\n",
    "print(type(df_can.index.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the dimensions of the dataframe, we use the `shape` instance variable of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of dataframe (rows, columns)\n",
    "df_can.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The main types stored in *pandas* objects are `float`, `int`, `bool`, `datetime64[ns]`, `datetime64[ns, tz]`, `timedelta[ns]`, `category`, and `object` (string). In addition, these dtypes have item sizes, e.g. `int64` and `int32`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the data set to remove a few unnecessary columns. We can use *pandas* `drop()` method as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pandas axis=0 represents rows (default) and axis=1 represents columns.\n",
    "df_can.drop(['AREA','REG','DEV','Type','Coverage'], axis=1, inplace=True)\n",
    "df_can.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns so that they make sense. We can use `rename()` method by passing in a dictionary of old and new names as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.rename(columns={'OdName':'Country', 'AreaName':'Continent', 'RegName':'Region'}, inplace=True)\n",
    "df_can.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add a 'Total' column that sums up the total immigrants by country over the entire period 1980 - 2013, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can['Total'] = df_can.sum(axis=1)\n",
    "df_can['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see how many null objects we have in the dataset as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's view a quick summary of each column in our dataframe using the `describe()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## *pandas* Intermediate: Indexing and Selection (slicing)<a id=\"3\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Column\n",
    "**There are two ways to filter on a column name:**\n",
    "\n",
    "Method 1: Quick and easy, but only works if the column name does NOT have spaces or special characters.\n",
    "```python\n",
    "    df.column_name               # returns series\n",
    "```\n",
    "\n",
    "Method 2: More robust, and can filter on multiple columns.\n",
    "\n",
    "```python\n",
    "    df['column']                  # returns series\n",
    "```\n",
    "\n",
    "```python \n",
    "    df[['column 1', 'column 2']]  # returns dataframe\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let's try filtering on the list of countries ('Country').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.Country  # returns a series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try filtering on the list of countries ('Country') and the data for years: 1980 - 1985.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can[['Country', 1980, 1981, 1982, 1983, 1984, 1985]] # returns a dataframe\n",
    "# notice that 'Country' is string, and the years are integers. \n",
    "# for the sake of consistency, we will convert all column names to string later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Row\n",
    "\n",
    "There are main 2 ways to select rows:\n",
    "\n",
    "```python\n",
    "    df.loc[label]    # filters by the labels of the index/column\n",
    "    df.iloc[index]   # filters by the positions of the index/column\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, notice that the default index of the dataset is a numeric range from 0 to 194. This makes it very difficult to do a query by a specific country. For example to search for data on Japan, we need to know the corresponding index value.\n",
    "\n",
    "This can be fixed very easily by setting the 'Country' column as the index using `set_index()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.set_index('Country', inplace=True)\n",
    "# tip: The opposite of set is reset. So to reset the index, we can use df_can.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: to remove the name of the index\n",
    "df_can.index.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let's view the number of immigrants from Japan (row 87) for the following scenarios:\n",
    "    1. The full row data (all columns)\n",
    "    2. For year 2013\n",
    "    3. For years 1980 to 1985\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. the full row data (all columns)\n",
    "df_can.loc['Japan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate methods\n",
    "df_can.iloc[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can[df_can.index == 'Japan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. for year 2013\n",
    "df_can.loc['Japan', 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate method\n",
    "# year 2013 is the last column, with a positional index of 36\n",
    "df_can.iloc[87, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. for years 1980 to 1985\n",
    "df_can.loc['Japan', [1980, 1981, 1982, 1983, 1984, 1984]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Method\n",
    "df_can.iloc[87, [3, 4, 5, 6, 7, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Let's view the number of immigrants from **Haiti** for the following scenarios: <br>1. The full row data (all columns) <br>2. For year 2000 <br>3. For years 1990 to 1995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.loc['Haiti']\n",
    "df_can.loc['Haiti', 2000]\n",
    "df_can.loc['Haiti', [1990, 1991, 1992, 1993, 1994, 1995]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for a sample python solution</summary>\n",
    "\n",
    "```python\n",
    "   # 1. the full row data (all columns)\n",
    "    df_can.loc['Haiti']\n",
    "    #or\n",
    "    df_can[df_can.index == 'Haiti']\n",
    "\n",
    "    # 2. for year 2000\n",
    "    df_can.loc['Haiti', 2000]\n",
    "           \n",
    "    #  3. for years 1990 to 1995\n",
    "    df_can.loc['Haiti', [1990, 1991, 1992, 1993, 1994, 1995]]\n",
    " ```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names that are integers (such as the years) might introduce some confusion. For example, when we are referencing the year 2013, one might confuse that when the 2013th positional index. \n",
    "\n",
    "To avoid this ambuigity, let's convert the column names into strings: '1980' to '2013'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.columns = list(map(str, df_can.columns))\n",
    "# [print (type(x)) for x in df_can.columns.values] #<-- uncomment to check type of column headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we converted the years to string, let's declare a variable that will allow us to easily call upon the full range of years:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for plotting later on\n",
    "years = list(map(str, range(1980, 2014)))\n",
    "years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create a list named 'year' using map function for years ranging from 1990 to 2013. <br>Then extract the data series from the dataframe df_can for Haiti using year list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for a sample python solution</summary>\n",
    "\n",
    "```python\n",
    "    #The correct answer is:\n",
    "    year = list(map(str, range(1990, 2014)))\n",
    "    haiti = df_can.loc['Haiti', year] # passing in years 1990 - 2013\n",
    "    \n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering based on a criteria <a id=\"4\"></a>\n",
    "To filter the dataframe based on a condition, we simply pass the condition as a boolean vector. \n",
    "\n",
    "For example, Let's filter the dataframe to show the data on Asian countries (AreaName = Asia).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create the condition boolean series\n",
    "condition = df_can['Continent'] == 'Asia'\n",
    "print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. pass this condition into the dataFrame\n",
    "df_can[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can pass multiple criteria in the same line.\n",
    "# let's filter for AreaNAme = Asia and RegName = Southern Asia\n",
    "\n",
    "df_can[(df_can['Continent']=='Asia') & (df_can['Region']=='Southern Asia')]\n",
    "\n",
    "# note: When using 'and' and 'or' operators, pandas requires we use '&' and '|' instead of 'and' and 'or'\n",
    "# don't forget to enclose the two conditions in parentheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Fetch the data where AreaName is 'Africa' and RegName is 'Southern Africa'. <br>Display the dataframe and find out how many instances are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for a sample python solution</summary>\n",
    "\n",
    "```python\n",
    "    df_can[(df_can['Continent']=='Africa') & (df_can['Region']=='Southern Africa')]\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Values of a Dataframe or Series <a id=\"5\"></a><br>\n",
    "You can use the `sort_values()` function is used to sort a DataFrame or a Series based on one or more columns. <br>You to specify the column(s) by which you want to sort and the order (ascending or descending). Below is the syntax to use it:-<br><br>\n",
    "```df.sort_values(col_name, axis=0, ascending=True, inplace=False, ignore_index=False)```<br><br>\n",
    "col_nam - the column(s) to sort by. <br>\n",
    "axis - axis along which to sort. 0 for sorting by rows (default) and 1 for sorting by columns.<br>\n",
    "ascending - to sort in ascending order (True, default) or descending order (False).<br>\n",
    "inplace - to perform the sorting operation in-place (True) or return a sorted copy (False, default).<br>\n",
    "ignore_index - to reset the index after sorting (True) or keep the original index values (False, default).<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort out dataframe df_can on 'Total' column, in descending order to find out the top 5 countries that contributed the most to immigration to Canada. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.sort_values(by='Total', ascending=False, axis=0, inplace=True)\n",
    "top_5 = df_can.head(5)\n",
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Find out top 3 countries that contributes the most to immigration to Canda in the year 2010. <br> Display the country names with the immigrant count in this year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for a sample python solution</summary>\n",
    "\n",
    "```python\n",
    "    df_can.sort_values(by='2010', ascending=False, axis=0, inplace=True)\n",
    "    top3_2010 = df_can['2010'].head(3)\n",
    "    top3_2010\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! you have learned how to wrangle data with Pandas. You will be using alot of these commands to preprocess the data before its can be used for data visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "\n",
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/aklson/\" target=\"_blank\">Alex Aklson</a>\n",
    "\n",
    "\n",
    "### Other Contributors\n",
    "[Jay Rajasekharan](https://www.linkedin.com/in/jayrajasekharan),\n",
    "[Ehsan M. Kermani](https://www.linkedin.com/in/ehsanmkermani),\n",
    "[Slobodan Markovic](https://www.linkedin.com/in/slobodan-markovic),\n",
    "[Weiqing Wang](https://www.linkedin.com/in/weiqing-wang-641640133/),\n",
    "[Dr. Pooja](https://www.linkedin.com/in/p-b28802262/)\n",
    "\n",
    "\n",
    "## Change Log\n",
    "\n",
    "\n",
    "|  Date (YYYY-MM-DD) | Version | Changed By    |  Change Description                   |\n",
    "|--------------------|---------|---------------|---------------------------------------|\n",
    "| 2023-06-08         | 2.5     | Dr. Pooja         |  Separated from original lab        |\n",
    "| 2021-05-29         | 2.4     | Weiqing Wang  |  Fixed typos and code smells.         |\n",
    "| 2021-01-20         | 2.3     | Lakshmi Holla |  Changed TOC cell markdown            |\n",
    "| 2020-11-20         | 2.2     | Lakshmi Holla |  Changed IBM box URL                  |\n",
    "| 2020-11-03         | 2.1     | Lakshmi Holla |  Changed URL and info method          |\n",
    "| 2020-08-27         | 2.0     | Lavanya       |  Moved Lab to course repo in GitLab   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
